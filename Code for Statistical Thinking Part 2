import csv
import re
import pandas as pd
import os
import datetime as dt
import io
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
import seaborn as sns
sns.set()
from bs4 import BeautifulSoup

"""how often do we get no-hitters? plotting the PDF"""
# Seed random number generator
np.random.seed(42)

# Compute mean no-hitter time: tau
tau = np.mean(nohitter_times)

# Draw out of an exponential distribution with parameter tau: inter_nohitter_time
inter_nohitter_time = np.random.exponential(tau, 100000)

# Plot the PDF and label axes
_ = plt.hist(inter_nohitter_time,
             bins=50, normed=True, histtype='step')
_ = plt.xlabel('Games between no-hitters')
_ = plt.ylabel('PDF')

# Show the plot
plt.show()


"""plotting the ecdf and the cdf"""
# Create an ECDF from real data: x, y
x, y = ecdf(nohitter_times)

# Create a CDF from theoretical samples: x_theor, y_theor
x_theor, y_theor = ecdf(inter_nohitter_time)

# Overlay the plots
plt.plot(x_theor, y_theor)
plt.plot(x, y, marker='.', linestyle='none')

# Margins and axis labels
plt.margins(0.02)
plt.xlabel('Games between no-hitters')
plt.ylabel('CDF')

# Show the plot
plt.show()


"""showing that the calculated tau is the optimal parameter"""
# Plot the theoretical CDFs
plt.plot(x_theor, y_theor)
plt.plot(x, y, marker='.', linestyle='none')
plt.margins(0.02)
plt.xlabel('Games between no-hitters')
plt.ylabel('CDF')

# Take samples with half tau: samples_half
samples_half = np.random.exponential(tau/2, size=10000)

# Take samples with double tau: samples_double
samples_double = np.random.exponential(2*tau, size=10000)

# Generate CDFs from these samples
x_half, y_half = ecdf(samples_half)
x_double, y_double = ecdf(samples_double)

# Plot these CDFs as lines
_ = plt.plot(x_half, y_half)
_ = plt.plot(x_double, y_double)

# Show the plot
plt.show()

"""construct scatter plot between illiteracy and fertility, calculate correlation coefficient between the two rates"""
# Plot the illiteracy rate versus fertility rate
_ = plt.plot(illiteracy, fertility, marker='.', linestyle='none')

# Set the margins and label axes
plt.margins(0.02)
_ = plt.xlabel('percent illiterate')
_ = plt.ylabel('fertility')

# Show the plot
plt.show()

# Show the Pearson correlation coefficient
print(pearson_r(illiteracy, fertility))

"""scatter plot again, calculate the slope, intercept of OLS line, graph the line on top of the scatter plot"""
# Plot the illiteracy rate versus fertility
_ = plt.plot(illiteracy, fertility, marker='.', linestyle='none')
plt.margins(0.02)
_ = plt.xlabel('percent illiterate')
_ = plt.ylabel('fertility')

# Perform a linear regression using np.polyfit(): a, b
a, b = np.polyfit(illiteracy, fertility, 1)

# Print the results to the screen
print('slope =', a, 'children per woman / percent illiterate')
print('intercept =', b, 'children per woman')

# Make theoretical line to plot
x = np.array([0,100])
y = a * x + b

# Add regression line to your plot
_ = plt.plot(x, y)

# Draw the plot
plt.show()

""" find where the parameter of slope(children/percent illiterate) is optimal, meaning lowest sum of the squares of residuals """
# Specify slopes to consider: a_vals
a_vals = np.linspace(0, 0.1, 200)

# Initialize sum of square of residuals: rss
rss = np.empty_like(a_vals)

# Compute sum of square of residuals for each value of a_vals
for i, a in enumerate(a_vals):
    rss[i] = np.sum((fertility - a*illiteracy - b)**2)

# Plot the RSS
plt.plot(a_vals, rss, '-')
plt.xlabel('slope (children per woman / percent illiterate)')
plt.ylabel('sum of square of residuals')

plt.show()


"""generating bootstrap replicates using np.random.choice(array, size) and comparing with original data, rainfall"""
for i in range(50):
    # Generate bootstrap sample: bs_sample
    bs_sample = np.random.choice(rainfall, size=len(rainfall))

    # Compute and plot ECDF from bootstrap sample
    x, y = ecdf(bs_sample)
    _ = plt.plot(x, y, marker='.', linestyle='none',
                 color='gray', alpha=0.1)

# Compute and plot ECDF from original data
x, y = ecdf(rainfall)
_ = plt.plot(x, y, marker='.')

# Make margins and label axes
plt.margins(0.02)
_ = plt.xlabel('yearly rainfall (mm)')
_ = plt.ylabel('ECDF')

# Show the plot
plt.show()


"""bootstrap replicate function, works on 1 dimensional arrays"""
def bootstrap_replicate_1d(data, func):
    bootstrap_sample = np.random.choice(data, len(data))
    return func(bootstrap_sample)

def draw_bs_reps(data, func, size=1):
    """Draw bootstrap replicates."""
    # Initialize array of replicates: bs_replicates
    bs_replicates = np.empty(size)
    # Generate replicates
    for i in range(size):
        bs_replicates[i] = bootstrap_replicate_1d(data, func)
    return bs_replicates
    
"""confidence interval on the rate of no-hitters using bootstrap replicates"""
nohitter_times = [843,1613,1101,215,684,814,278,324,161,219,545,715,966,624,29,450,107,20,
91,1325,124,1468,104,1309,429,62,1878,1104,123,251,93,188,983,166,96,702,
23,526,26,299,59,39,12,2,308,1114,813,887,645,2088,42,2090,11,886,1665,
1084,2900,2432,750,4021,1070,1765,1322,26,548,1525,77,2181,2752,127,2147,
211,41,1575,151,479,697,557,2267,542,392,73,603,233,255,528,397,1529,1023,1194,
462,583,37,943,996,480,1497,717,224,219,1531,498,44,288,267,600,52,269,1086,386,
176,2199,216,54,675,1243,463,650,171,327,110,774,509,8,197,136,12,1124,64,380,
811,232,192,731,715,226,605,539,1491,323,240,179,702,156,82,1397,354,778,
603,1001,385,986,203,149,576,445,180,1403,252,675,1351,2983,1568,45,899,
3260,1025,31,100,2055,4043,79,238,3931,2351,595,110,215,0,563,206,660,242,
577,179,157,192,192 ,1848 ,792, 1693, 55,388 ,225,1134,1172,1555,31,
1582,1044,378,1687,2915,280,765,2819,511,1521,745,2491,580,
2072,6450,578,745,1075,1103,1549,1520,138,1202,296,277,351,391,950,459,62,1056,
1128,139,420,87,71,814,603,1349,162,1027,783,326,101,876,381,905,156,419, 239,119,129,467]

print (np.mean(nohitter_times))

# Draw bootstrap replicates of the mean no-hitter time (equal to tau): bs_replicates
bs_replicates = draw_bs_reps(nohitter_times, np.mean, 10000)

# Compute the 95% confidence interval: conf_int
conf_int = np.percentile(bs_replicates, [2.5, 97.5])

# Print the confidence interval
print('95% confidence interval =', conf_int, 'games')

# Plot the histogram of the replicates
_ = plt.hist(bs_replicates, bins=50, normed=True)
_ = plt.xlabel(r'$\tau$ (games)')
_ = plt.ylabel('PDF')

# Show the plot
plt.show()


def draw_bs_pairs_linreg(x, y, size=1):
    """Perform pairs bootstrap for linear regression."""

    # Set up array of indices to sample from: inds
    inds = np.arange(len(x))

    # Initialize replicates: bs_slope_reps, bs_intercept_reps
    bs_slope_reps = np.empty(size)
    bs_intercept_reps = np.empty(size)

    # Generate replicates
    for i in range(size):
        bs_inds = np.random.choice(inds, size=len(inds))
        bs_x, bs_y = x[bs_inds], y[bs_inds]
        bs_slope_reps[i], bs_intercept_reps[i] = np.polyfit(bs_x, bs_y, 1)

    return bs_slope_reps, bs_intercept_reps
    
def permutation_sample(data1, data2):
    """Generate a permutation sample from two data sets."""

    # Concatenate the data sets: data
    data = np.concatenate((data1, data2))

    # Permute the concatenated array: permuted_data
    permuted_data = np.random.permutation(data)

    # Split the permuted array into two: perm_sample_1, perm_sample_2
    perm_sample_1 = permuted_data[:len(data1)]
    perm_sample_2 = permuted_data[len(data1):]

    return perm_sample_1, perm_sample_2
    
 rain_july =[  66.2,   39.7,   76.4,   26.5,   11.2,   61.8 ,   6.1,   48.4,   89.2,  104.,    34.,
   60.6,   57.1,   79.1,   90.9,   32.3,   63.8,   78.2,   27.5,   43.4,   30.1,
   17.3,  77.5,   44.9,   92.2,   39.6,   79.4,   66.1,   53.5,   98.5,   20.8,
   55.5,   39.6,   56.,    65.1,   14.8,   13.2,   88.1,    8.4,   32.1,   19.6,
   40.4,    2.2,   77.5,  105.4,   77.2,   38.,   27.1,  111.8,   17.2,   26.7,
   23.3,   77.2,   87.2,   27.7,   50.6,   60.3,   15.1,    6.,    29.4,   39.3,
   56.3,   80.4,   85.3,   68.4,   72.5,   13.3,   28.4,   14.7,   37.4,   49.5,
   57.2,   85.9,   82.1,   31.8,  126.6,   30.7,   41.4,   33.9,   13.5,   99.1,
   70.2,   91.8,   61.3,   13.7,   54.9,   62.5,   24.2,   69.4,   83.1,   44.,
   48.5,   11.9,   16.6,   66.4,   90.,    34.9,  132.8,   33.4,  225.,     7.6,
   40.9,   76.5,   48.,   140.,    55.9,   54.1,   46.4,   68.6,   52.2,  108.3,
   14.6,   11.3,   29.8,  130.9,  152.4,   61.,   46.6,  43.9,   30.9,  111.1,
   68.5,   42.2,    9.8,  285.6,   56.7,  168.2,   41.2,   47.8,  166.6,   37.8,
   45.4,   43.2,]
rain_november = [  83.6,   30.9,   62.2,   37.,    41.,   160.2,   18.2,  122.4,   71.3,   44.2,
   49.1,   37.6,  114.5,   28.8,   82.5,   71.9,   50.7,   67.7,  112.,    63.6,
   42.8,   57.2,  99.1,   86.4,   84.4,   38.1,   17.7,  102.2,  101.3,   58.,    82.,
  101.4,   81.4,  100.1,   54.6,   39.6,   57.5,   29.2,   48.8,   37.3,  115.4,
   55.6,   62.,    95.,    84.2,  118.1,  153.2,   83.4,  104.7,   59.,    46.4,
   50.,   147.6,   76.8,   59.9,  101.8,  136.6,  173.,    92.5,   37.,    59.8,
  142.1,    9.9,  158.2,   72.6,   28.,   112.9,  119.3,  199.2,   50.7,   44.,
  170.7,   67.2,   21.4,   61.3,  15.6,  106.,   116.2,   42.3,   38.5,  132.5,
   40.8,  147.5,   93.9,   71.4,   87.3,  163.7,  141.4,   62.6,   84.9,   28.8,
  121.1,   28.6,   32.4,  112.,    50.,    96.9,   81.8,   70.4,  117.5,   41.2,
  124.9,   78.2,   93.,    53.5,   50.5,   42.6,   47.9,  73.1,  129.1,   56.9,
  103.3,   60.5,  134.3,   93.1,   49.5,   48.2,  167.9,   27.,   111.1,   55.4,
   36.2,   57.4,   66.8,   58.3,   60.,   161.6,  112.7,   37.4,  110.6,   56.6,
   95.8,  126.8]

"""visualize permutation sampling"""
for i in range(50):
    # Generate permutation samples
    perm_sample_1, perm_sample_2 = permutation_sample(rain_july, rain_november)


    # Compute ECDFs
    x_1, y_1 = ecdf(perm_sample_1)
    x_2, y_2 = ecdf(perm_sample_2)

    # Plot ECDFs of permutation sample
    _ = plt.plot(x_1, y_1, marker='.', linestyle='none',
                 color='red', alpha=0.02)
    _ = plt.plot(x_2, y_2, marker='.', linestyle='none',
                 color='blue', alpha=0.02)

# Create and plot ECDFs from original data
x_1, y_1 = ecdf(rain_july)
x_2, y_2 = ecdf(rain_november)
_ = plt.plot(x_1, y_1, marker='.', linestyle='none', color='red')
_ = plt.plot(x_2, y_2, marker='.', linestyle='none', color='blue')

# Label axes, set margin, and show plot
plt.margins(0.02)
_ = plt.xlabel('monthly rainfall (mm)')
_ = plt.ylabel('ECDF')
plt.show()
print ('observation: the permutation samples are the middle band, and the original datas ecdfs are separate. Signals that July & november ')


def draw_perm_reps(data_1, data_2, func, size=1):
    """Generate multiple permutation replicates."""

    # Initialize array of replicates: perm_replicates
    perm_replicates = np.empty(size)

    for i in range(size):
        # Generate permutation sample
        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)

        # Compute the test statistic
        perm_replicates[i] = func(perm_sample_1, perm_sample_2)

    return perm_replicates
    
#data: A is an adult frog, B is a juvenile frog. Their respective numbers are the measure of the impact of the force of their tongues
frog_data = np.array([['A', 1.612], ['A', 0.605],['A', 0.327],['A', 0.946],['A', 0.541],['A', 1.539],['A', 0.529],['A', 0.628],
       ['A', 1.453],['A', 0.297],['A', 0.703],['A', 0.269],['A', 0.751],['A', 0.245],['A', 1.182],['A', 0.515],
       ['A', 0.435],['A', 0.383],['A', 0.457],['A', 0.73],['B', 0.172],['B', 0.142],['B', 0.037],['B', 0.453],
       ['B', 0.355],['B', 0.022],['B', 0.502],['B', 0.273],['B', 0.72],['B', 0.582],['B', 0.198],['B', 0.198],
       ['B', 0.597], ['B', 0.516],['B', 0.815],['B', 0.402],['B', 0.605],['B', 0.711],['B', 0.614],['B', 0.468]])
df= pd.DataFrame(frog_data)
df.columns = ['ID', 'impact_force']

"""EDA of the frog_data using a swarm plot"""
# Make bee swarm plot
_ = sns.swarmplot(x=df['ID'], y=df['impact_force'], data=df)

# Label axes
_ = plt.xlabel('frog')
_ = plt.ylabel('impact force (N)')

# Show the plot
plt.show()

# frog data, forces of A and B
force_a = [ 1.612,  0.605,  0.327,  0.946,  0.541,  1.539,  0.529,  0.628,  1.453,  0.297,
  0.703,  0.269, 0.751,  0.245,  1.182,  0.515,  0.435,  0.383,  0.457,  0.73 ]
force_b = [ 0.172,  0.142,  0.037,  0.453,  0.355,  0.022,  0.502,  0.273, 0.72 ,  0.582,  
           0.198,  0.198,  0.597,  0.516,  0.815,  0.402, 0.605,  0.711,  0.614,  0.468]
def diff_of_means(data_1, data_2):
    """Difference in means of two arrays."""

    # The difference of means of data_1, data_2: diff
    diff = np.mean(data_1) - np.mean(data_2)

    return diff

# Compute difference of mean impact force from experiment: empirical_diff_means
empirical_diff_means = diff_of_means(force_a, force_b)

# Draw 10,000 permutation replicates: perm_replicates
perm_replicates = draw_perm_reps(force_a, force_b,
                                 diff_of_means, size=10000)

# Compute p-value: p
p = np.sum(perm_replicates >= empirical_diff_means) / len(perm_replicates)

# Print the result
print('p-value =', p)
# low p value indicates that there is a low chance that the means of the two frogs are actually the same.
# the data indicates that the means of Frog A and Frog B are statistically significant


"""A/B testing"""
# clickthrough_A, clickthrough_B: arrays of 0 and 1, 1 being click and 0 being no click
def diff_fraction(data_A, data_B):
    frac_A = np.sum(data_A)/len(data_A)
    frac_B = np.sum(data_B)/len(data_B)
    return frac_B - frac_A
    
 """did party affiliation make a difference in the vote of the civil rights act of 1964?"""
# Construct arrays of data: dems, reps
dems = np.array([True] * 153 + [False] * 91) # democrats: 153 yays, 91 nays
reps = np.array([True] * 136 + [False] * 35) # republicans: 136 yays, 35 nays

def frac_yay_dems(dems, reps):
    """Compute fraction of Democrat yay votes."""
    frac = np.sum(dems) / len(dems)
    return frac

# Acquire permutation samples: perm_replicates
perm_replicates = draw_perm_reps(dems, reps, frac_yay_dems, 10000)

# Compute and print p-value: p
p = np.sum(perm_replicates <= 153/244) / len(perm_replicates)
print('p-value =', p)

# low p value indicates that party affiliation did have an impact on the voting


# Compute observed correlation: r_obs
r_obs = pearson_r(illiteracy, fertility)

# Initialize permutation replicates: perm_replicates
perm_replicates = np.empty(10000)

# Draw replicates
for i in range(10000):
    # Permute illiteracy measurments: illiteracy_permuted
    illiteracy_permuted = np.random.permutation(illiteracy)

    # Compute Pearson correlation
    perm_replicates[i] = pearson_r(illiteracy_permuted, fertility)

# Compute p-value: p
p = np.sum(perm_replicates>= r_obs)/len(perm_replicates)
print('p-val =', p)
